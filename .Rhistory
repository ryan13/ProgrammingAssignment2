scale_color_manual(name=&quot;Type of Mean&quot;,
values=c(ealred, ealorange, ealblue),
breaks=c(&quot;arithmetic&quot;, &quot;harmonic&quot;, &quot;geometric&quot;),
labels=c(paste(&quot;Arithmetic: &quot;, round(results$arithmetic, digits=2)),
paste(&quot;Harmonic: &quot;, round(results$harmonic, digits=2)),
paste(&quot;Geometric: &quot;, round(results$geometric, digits=2)))) +
scale_x_discrete(breaks=NULL) +
labs(x=&quot;Observations&quot;, y=NULL) +
theme(panel.background=element_rect(fill=eallighttan))
return(g)
}
#### Comparison with Normally Distributed Sample ####
# First generate 'random' set of n numbers with mean of m. These will be normally
# distributed so you expect arithmetic mean, harmonic mean, and geometric
# mean to be fairly consistent.
n &lt;- 25
m &lt;- 5
sample &lt;- data.frame(&quot;value&quot;=rnorm(n=n, mean=m))
sample$obs &lt;- rownames(sample)
# Next plot the three means, compared with the sample population
g &lt;- plot.means(sample)
g &lt;- g + ggtitle(&quot;Mean Comparison with\nNormally Distributed Sample&quot;)
g
# ggsave(&quot;test.png&quot;)
#### Comparison based on Sample with an Outlier
# Add a few outliers to distort the population
sample.outliers &lt;- sample
sample.outliers[n-2, 1] &lt;- m^2.5
g.outlier &lt;- plot.means(sample.outliers)
g.outlier &lt;- g.outlier + ggtitle(&quot;Mean Comparison using\nSample with Outliers&quot;)
g.outlier
library(ggplot2)
library(reshape2)
install.packages(ggplot2)
install.packages("ggplot2")
d <-  sample(1:40, 6, replace=F)
d
geometricMean(d)
install.packacge("lattice")
install.packacges("lattice")
install.packages("lattice")
library(moments)
install.packages("moments")
quit()
install.packagees("skewness")
install.packages("moments")
install.packages("moments",lib="c:/r-with")
install.packages("ggplot2",lib="c:/r-with")
install.packages("lattice",lib="c:/r-with")
library(moments)
library(lattice)
ds = read.csv("http://www.math.smith.edu/r/data/help.csv")
ds$gender = ifelse(ds$female==1, "female", "male")
densityplot(~ cesd, data=ds, groups=gender, auto.key=TRUE)
with(ds, tapply(cesd, gender, skewness))
install.packages("moments",lib="c:/r-with")
library(moments)
library("moments",lib='c:/r-with')
with(ds, tapply(cesd, gender, skewness))
data <- read.table("2401.dat", header=T)
> attach(data)
data <- read.table("2401.dat", header=T)
attach(data)
attach(data)
data <- read.table("2401.dat", header=T)
skessness(ds)
skewness(ds)
ds
skewness()
skewness ?
)
? skewness
skewness(ds$male, na.rm = FALSE)
set.seed(1234)
skewness(rnorm(1000))
class(ds)
sapply(ds,class)
head(ds)
x <- c(0:10, 50)
xm <- mean(x)
xm
c(xm, mean(x, trim = 0.10))
x
library(dataset)
library(datasets)
data(women)
mad(women$height)
install.packages("cca",lib="c:/r-with")
install.packages("CCA",lib="c:/r-with")
install.packages("GGally",lib="c:/r-with")
q()
attached <- search()
attached[!grepl("package", attached)]
attach(iris)
iris
?sweep
require(stats)
med.att <- apply(attitude, 2, median)
med.att
stats
sweep(data.matrix(attitude), 2, med.att)
A <- array(1:24, dim = 4:2)
A
dim(A)
A[1]
A[2]
A[3]
A[4]
sweep(A, 1, 5)
# We will use the built-in iris data set.
# We will consider the entire data set (all three species)
attach(iris)
# We will standardize the variables first
# by dividing by each column's standard deviation:
# (we will remove column 5, the species labels)
iris.std <- sweep(iris[,-5], 2, sqrt(apply(iris[,-5],2,var)), FUN="/")
sepal.meas <- iris.std[,1:2]
petal.meas <- iris.std[,3:4]
### Doing the CCA the long way:
# Finding blocks of the correlation matrix:
R11 <- cor(sepal.meas)
R22 <- cor(petal.meas)
R12 <- c(cor(sepal.meas[,1], petal.meas[,1]), cor(sepal.meas[,1], petal.meas[,2]),
cor(sepal.meas[,2], petal.meas[,1]), cor(sepal.meas[,2], petal.meas[,2]))
R12 <- matrix(R12, ncol=ncol(R22), byrow=T) # R12 has q2 columns, same as number of petal measurements
R21 <- t(R12)  # R21=transpose of R12
# Finding the E1 and E2 matrices:
E1 <- solve(R11) %*% R12 %*% solve(R22) %*% R21
E2 <- solve(R22) %*% R21 %*% solve(R11) %*% R12
# print(E1)
# print(E2)
eigen(E1)
eigen(E2)
# The canonical correlations are:
canon.corr <- sqrt(eigen(E1)$values)
canon.corr
canon.corr
dim(canon.corr)
type(canon.corr)
summary(canon.corr)
attached <- search()
attached[!grepl("package", attached)]
attach(mtcar)
attach(mtcars)
attach(breast-cancer)
attach(glass)
attach(weather)
attach(iris)
# We will standardize the variables first
# by dividing by each column's standard deviation:
# (we will remove column 5, the species labels)
iris.std <- sweep(iris[,-5], 2, sqrt(apply(iris[,-5],2,var)), FUN="/")
sepal.meas <- iris.std[,1:2]
petal.meas <- iris.std[,3:4]
### Doing the CCA the long way:
# Finding blocks of the correlation matrix:
R11 <- cor(sepal.meas)
R22 <- cor(petal.meas)
R12 <- c(cor(sepal.meas[,1], petal.meas[,1]), cor(sepal.meas[,1], petal.meas[,2]),
cor(sepal.meas[,2], petal.meas[,1]), cor(sepal.meas[,2], petal.meas[,2]))
R12 <- matrix(R12, ncol=ncol(R22), byrow=T) # R12 has q2 columns, same as number of petal measurements
R21 <- t(R12)  # R21=transpose of R12
# Finding the E1 and E2 matrices:
E1 <- solve(R11) %*% R12 %*% solve(R22) %*% R21
E2 <- solve(R22) %*% R21 %*% solve(R11) %*% R12
# print(E1)
# print(E2)
eigen(E1)
eigen(E2)
# The canonical correlations are:
canon.corr <- sqrt(eigen(E1)$values)
canon.corr
eigen(E1)
eigen(E1)$values
source("http://bioconductor.org/biocLite.R")
source("http://bioconductor.org/biocLite.R",lib="c:/r-with")
?source
source("http://bioconductor.org/biocLite.R",lib="c:/r-with")
source("http://bioconductor.org/biocLite.R")
source("http://bioconductor.org/biocLite.R")
quit()
install.packages("slidify")
install.packages("devtools")
install.packages("devtool",lib="/data/Rpackages")
install.packages("devtools",lib="/data/Rpackages")
library(devtools)
savehistory()
quit()
quit()
library(plyr)
biocLite()
source("http://bioconductor.org/biocLite.R")
biocLite()
install.packages("rpart",lib="c:\R")
install.packages("rpart",lib="c:/R")
source("http://bioconductor.org/biocLite.R")
biocLite()
library(rpart)
quit
quit()
quit
quit()
library(ggplot2)
?read.table
install.packages(“RMySQL”, type = “source”)
install.packages(“RMySQL”, type = “source”)
install.packages(“RMySQL”)
install.packages("Rmysql",type="source")
install.packages("RMYSQL",type="source")
install.packages("RMySQL",type="source")
library(RMySQL)
library(RMYSQL)
install.packages("RMySQL",type="source")
library(RMYSQL)
library(RMySQL)
library(devtools)
find_tools()
shortPathName("C:\\Program Files\\MySQL\\MySQL Server 5.6")
install.packages("RMySQL",type="source")
find_rtools()
quit()
install.packages('RMySQL',type='source')
restart()
install.packages('RMySQL',type='source')
quit()
install.packages('RMySQL',type='source')
install.packages('RMySQL',type='source')
install.packages('RMySQL',type='source')
install.packages("RMySQL",type="source")
install.packages("RMySQL",type="source")
install.packages("RMySQL",type="source")
install.packages("RMySQL",type="source")
library(RMySQL)
quit()
library(devtools)
find_rtools()
install.packages("RMySQL",type="source")
install.packages("MySQL",type="source")
install.packages("RMySQL",type="source")
install.packages("RMySQL",type="source")
install.packages("RMySQL",type="source")
install.packages("IRanges")
source("http://bioconductor.org/biocLite.R")
biocLite("IRange")
biocLite("Biobase")
biocLite("GEOquery")
library(devtools)
quit()
library(BioBase)
library(Biobase)
library(dagdata)
source("http:\\bioconductor.org")
source("http://bioconductor.org/biocLite.R")
biocLite("dagdata")
library(dagdata)
library(dagdata)
library(Biobase)
library(dagdata)
install.packages("dagdata")
source("http://bioconductor.org/biocLite.R")
biocLite("dagdata")
library(limma)
phenoData <- data.frame(treatment=factor(rep(c("control","drug"),each=4)),
sex=factor(rep(rep(c("female","male"),each=2),2)))
library(devtools)
install_github('dagdata','genomicsclass')
install_github("rafalib","ririzarr")
library(rafalib)
source("http://bioconductor.org/biocLite.R")
biocLite("genefilter")
library(preprocess)
library(preprocessCore)
library(SpikeIn)
source("http://bioconductor.org/biocLite.R")
source("http://bioconductor.org/biocLite.R"
)
source("http://bioconductor.org/biocLite.R")
biocLite("SpikeIn")
quit()
cube <- function(x, n) {
x^3
}
cube(3)
x <- 1:10
if(x > 5) {
x <- 0
}
f <- function(x) {
g <- function(y) {
y + z
}
z <- 4
x + g(x)
}
z <- 10
f(3)
x <- 5
y <- if(x < 3) {
NA
} else {
10
}
y
h <- function(x, y = NULL, d = 3L) {
z <- cbind(x, d)
if(!is.null(y))
z <- z + y
else
z <- z + f
g <- x + y / z
if(d == 3L)
return(g)
g <- g + 10
g
}
library(datasets)
data(iris)
>iris
?iris
summary(iris)
mean(Sepal.Length)
mean(iris$Sepal.Length)
apply(iris[, 1:4], 1, mean)
iris[.1:4]
class(iris)
str(iris)
apply(iris[, 1:4], 2, mean)
?apply
x <- cbind(x1 = 3, x2 = c(4:1, 2:5))
x
dimnames(x)[[1]] <- letters[1:8]
apply(x, 2, mean, trim = .2)
apply(x, 1, mean, trim = .2)
apply(iris[, 1:4], 2, mean)
library(datasets)
data(mtcars)
apply(mtcars, 2, mean)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
?mtcar
?mtcars
split(mtcars$mpg, mtcars$cyl)
mtcars$mpg
head(mtcars)
split(mtcars$mpg, mtcars$cyl)
tapply(mtcars$cyl, mtcars$mpg, mean)
# Assignment2: Caching the Inverse of a Matrix
## creates a wrapper object around a matrix that can optionally store
## its inverse. exposes setters and getters for both. invalidates
## cache on set.
makeCacheMatrix <- function(x = matrix()) {
inverse <- NULL
set <- function(y) {
x <<- y
inverse <<- NULL
}
get <- function() x
setinv <- function(inv) inverse <<- inv
getinv <- function() inverse
list(set = set, get = get, setinv = setinv, getinv = getinv)
}
## computes the inverse of a matrix with caching.
## expects a wrapped matrix as returned from makeCacheMatrix. first
## checks cache in the object passed in for the presence of the result
## of a previous run. if found returns that, otherwise computes the
## result and then stores it in the cache as well as returning it to
## the caller
cacheSolve <- function(x) {
inverse <- x$getinv()
if(!is.null(inverse)) {
message("getting cached data")
return(inverse)
}
data <- x$get()
inverse <- solve(data)
x$setinv(inverse)
inverse
}
getwd()
setwd("c:/person/reproducibility")
dir()
unzip("repdata_data_activity.zip")
activity <- read.csv("activity.csv")
```
## What is the mean total number of steps taken per day?
1. Make a histogram of the total number of steps taken each day
```{r}
steps.date <- aggregate(steps ~ date, data=activity, FUN=sum)
barplot(steps.date$steps, names.arg=steps.date$date, xlab="date", ylab="steps")
```
2. Calculate and report the **mean** and **median** total number of
steps taken per day
```{r}
mean(steps.date$steps)
median(steps.date$steps)
```
## What is the average daily activity pattern?
1. Make a time series plot (i.e. `type = "l"`) of the 5-minute
interval (x-axis) and the average number of steps taken, averaged
across all days (y-axis)
```{r}
steps.interval <- aggregate(steps ~ interval, data=activity, FUN=mean)
plot(steps.interval, type="l")
```
2. Which 5-minute interval, on average across all the days in the
dataset, contains the maximum number of steps?
```{r}
steps.interval$interval[which.max(steps.interval$steps)]
```
## Imputing missing values
1. Calculate and report the total number of missing values in the
dataset (i.e. the total number of rows with `NA`s)
```{r}
sum(is.na(activity))
```
2. Devise a strategy for filling in all of the missing values in the
dataset. The strategy does not need to be sophisticated. For
example, you could use the mean/median for that day, or the mean
for that 5-minute interval, etc.
I will use the means for the 5-minute intervals as fillers for missing
values.
3. Create a new dataset that is equal to the original dataset but with
the missing data filled in.
str(activity)
head(activity)
tail(activity)
str(steps.interval)
head(steps.interval)
str(activity)
?merge
activity <- merge(activity, steps.interval, by="interval", suffixes=c("",".y"))
head(activity)
nas <- is.na(activity$steps)
head(nas)
activities$steps.y
activity$steps.y
activity$steps[nas] <- activity$steps.y[nas]
activity <- activity[,c(1:3)]
activity
activity <- read.csv("activity.csv")
```
## What is the mean total number of steps taken per day?
1. Make a histogram of the total number of steps taken each day
```{r}
steps.date <- aggregate(steps ~ date, data=activity, FUN=sum)
barplot(steps.date$steps, names.arg=steps.date$date, xlab="date", ylab="steps")
```
2. Calculate and report the **mean** and **median** total number of
steps taken per day
```{r}
mean(steps.date$steps)
median(steps.date$steps)
```
## What is the average daily activity pattern?
1. Make a time series plot (i.e. `type = "l"`) of the 5-minute
interval (x-axis) and the average number of steps taken, averaged
across all days (y-axis)
```{r}
steps.interval <- aggregate(steps ~ interval, data=activity, FUN=mean)
plot(steps.interval, type="l")
```
2. Which 5-minute interval, on average across all the days in the
dataset, contains the maximum number of steps?
```{r}
steps.interval$interval[which.max(steps.interval$steps)]
```
## Imputing missing values
1. Calculate and report the total number of missing values in the
dataset (i.e. the total number of rows with `NA`s)
```{r}
sum(is.na(activity))
head (activity)
steps.interval
activity
nrow(activity)
nrow(stpes)
nrow(steps)
nrow(steps.interval)
steps.interval
activity <- merge(activity, steps.interval, by="interval", suffixes=c("",".y"))
activity
activity <- read.csv("activity.csv")
steps.date <- aggregate(steps ~ date, data=activity, FUN=sum)
hist(steps.date$steps,xlab="total amounts", ylab="frequencies")
mean(steps.date$steps)
median(steps.date$steps)
steps.interval <- aggregate(steps ~ interval, data=activity, FUN=mean)
plot(steps.interval, type="l")
t
sum(is.na(activity))
activity[400:500,]
steps.interval[100:200,]
activity <- merge(activity, steps.interval, by="interval")
head(activity)
nas <- is.na(activity$steps)
nas <- is.na(activity$steps.x)
activity$steps.x[nas] <- activity$steps.y[nas]
activity <- activity[,c(1:3)]
str(activity)
if weekdays(as.Date(date)) %in% c("Saturday","Sunday" ) "weekend" else "weekday"
if (weekdays(as.Date(date))) %in% c("Saturday","Sunday" ) "weekend" else "weekday"
if (weekdays(as.Date(date)) %in% c("Saturday","Sunday" )) "weekend" else "weekday"
date <-"05012014"
date <-"05/01/2014"
if (weekdays(as.Date(date)) %in% c("Saturday","Sunday" )) "weekend" else "weekday"
activity$daytype <- as.factor(sapply(activity$date, if (weekdays(as.Date(date)) %in% c("Saturday","Sunday" )) "weekend" else "weekday"
)
)
setwd("c:/person/rprogramming/Programming2")
setwd("c:/person/rprogramming/ProgrammingAssignment2")
library(datasets)
data(mtcars)
str(cars)
